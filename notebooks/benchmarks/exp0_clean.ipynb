{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exp0: Clean baseline (thin notebook)\n",
        "\n",
        "Purpose:\n",
        "- Quick sanity check of the classical baseline on clean data.\n",
        "- Uses reusable modules in `src/sir` to avoid code duplication.\n",
        "\n",
        "How to use:\n",
        "1) Adjust the config cell (seed, limit, test_size, etc.).\n",
        "2) Run all cells to compute metrics on a small subset.\n",
        "3) For full runs and CSV outputs, use:\n",
        "   `python scripts/exp0_run.py --test-size 0.1 --max-test 200 --n-starts 5`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "repo_root = Path.cwd()\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.append(str(repo_root))\n",
        "\n",
        "from src.sir.config import DEFAULTS, set_global_seed\n",
        "from src.sir.datasets import load_sir_pkl, build_Xy_I_only, train_val_test_split\n",
        "from src.sir.baseline import fit_mse\n",
        "from src.sir.metrics import per_param_metrics, timing_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "seed = 42\n",
        "set_global_seed(seed)\n",
        "rng = np.random.default_rng(seed)\n",
        "\n",
        "data_path = DEFAULTS.data_path\n",
        "limit = 5000  # reduce for quick sanity checks\n",
        "test_size = 0.10\n",
        "val_size = 0.10\n",
        "n_starts = 3\n",
        "max_test = 200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = load_sir_pkl(data_path, limit=limit, rng=rng)\n",
        "X, y = build_Xy_I_only(data, normalize=None)\n",
        "\n",
        "splits = train_val_test_split(\n",
        "    X, y, test_size=test_size, val_size=val_size, rng=rng, return_indices=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = splits['X_test']\n",
        "y_test = splits['y_test']\n",
        "\n",
        "idx = rng.choice(X_test.shape[0], size=min(max_test, X_test.shape[0]), replace=False)\n",
        "X_fit = X_test[idx]\n",
        "y_fit = y_test[idx]\n",
        "\n",
        "preds = []\n",
        "times = []\n",
        "for i in range(X_fit.shape[0]):\n",
        "    fit = fit_mse(X_fit[i], n_starts=n_starts, rng=np.random.default_rng(seed + i))\n",
        "    preds.append(fit.params[:2])\n",
        "    times.append(sum(fit.times))\n",
        "\n",
        "preds = np.asarray(preds)\n",
        "metrics = per_param_metrics(y_fit, preds)\n",
        "metrics.update(timing_summary(np.asarray(times)))\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run full benchmark with:\n",
        "\n",
        "```bash\n",
        "python scripts/exp0_run.py --test-size 0.1 --max-test 200 --n-starts 5\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "mimetype": "text/x-python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}