{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fit (Neural Networks): SIR data without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 13:43:38.844753: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-15 13:43:38.856689: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-15 13:43:38.871949: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-15 13:43:38.876466: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-15 13:43:38.888398: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1736959421.533701  614295 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736959421.583925  614295 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736959421.584194  614295 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Path\n",
    "import pickle as pkl\n",
    "data_path = '../../data/raw/simulated/SIR'\n",
    "with open(f'{data_path}/sir.pkl', 'rb') as f:\n",
    "    data_sim = pkl.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division Training/Validation/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (70000, 1001)\n",
      "X_val shape: (20000, 1001)\n",
      "X_test shape: (10000, 1001)\n",
      "y_train shape: (70000, 2)\n",
      "y_val shape: (20000, 2)\n",
      "y_test shape: (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data\n",
    "X = [] # X will be the data from infected people\n",
    "y = [] # y will be the parameters from that simulation\n",
    "\n",
    "for simulation in data_sim:\n",
    "    compartment_data = simulation[0]  # S, I, R matrix\n",
    "    parameters = simulation[2]  # [beta, gamma]\n",
    "    \n",
    "    # Extract I values\n",
    "    I_values = compartment_data[:, 1]  # second column columna (I compartment)\n",
    "    \n",
    "    X.append(I_values)  # Add to the characteristic list\n",
    "    y.append(parameters)  # Add to label list\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X) \n",
    "y = np.array(y) \n",
    "\n",
    "# First division: 90% training + validation, 10% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Second división: 70% training, 20% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=2/9, random_state=42)\n",
    "\n",
    "# Imprimir formas para verificar\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 0.4877 - r2_score: -3.7531 - val_loss: 0.0040 - val_r2_score: 0.9669\n",
      "Epoch 2/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0032 - r2_score: 0.9765 - val_loss: 0.0028 - val_r2_score: 0.9832\n",
      "Epoch 3/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0039 - r2_score: 0.9737 - val_loss: 0.0015 - val_r2_score: 0.9904\n",
      "Epoch 4/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0032 - r2_score: 0.9809 - val_loss: 0.0049 - val_r2_score: 0.9757\n",
      "Epoch 5/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0030 - r2_score: 0.9814 - val_loss: 0.0018 - val_r2_score: 0.9891\n",
      "Epoch 6/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0028 - r2_score: 0.9830 - val_loss: 0.0016 - val_r2_score: 0.9907\n",
      "Epoch 7/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0022 - r2_score: 0.9861 - val_loss: 0.0013 - val_r2_score: 0.9911\n",
      "Epoch 8/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0021 - r2_score: 0.9869 - val_loss: 0.0018 - val_r2_score: 0.9896\n",
      "Epoch 9/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0024 - r2_score: 0.9852 - val_loss: 0.0014 - val_r2_score: 0.9913\n",
      "Epoch 10/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0019 - r2_score: 0.9883 - val_loss: 0.0011 - val_r2_score: 0.9940\n",
      "Epoch 11/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0018 - r2_score: 0.9880 - val_loss: 0.0011 - val_r2_score: 0.9937\n",
      "Epoch 12/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0019 - r2_score: 0.9884 - val_loss: 0.0011 - val_r2_score: 0.9939\n",
      "Epoch 13/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0015 - r2_score: 0.9905 - val_loss: 0.0011 - val_r2_score: 0.9947\n",
      "Epoch 14/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0015 - r2_score: 0.9905 - val_loss: 0.0017 - val_r2_score: 0.9896\n",
      "Epoch 15/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0013 - r2_score: 0.9916 - val_loss: 9.6701e-04 - val_r2_score: 0.9944\n",
      "Epoch 16/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0014 - r2_score: 0.9913 - val_loss: 0.0033 - val_r2_score: 0.9772\n",
      "Epoch 17/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0012 - r2_score: 0.9921 - val_loss: 0.0010 - val_r2_score: 0.9935\n",
      "Epoch 18/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0012 - r2_score: 0.9918 - val_loss: 0.0019 - val_r2_score: 0.9892\n",
      "Epoch 19/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0011 - r2_score: 0.9928 - val_loss: 0.0013 - val_r2_score: 0.9916\n",
      "Epoch 20/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0010 - r2_score: 0.9934 - val_loss: 8.2391e-04 - val_r2_score: 0.9926\n",
      "Epoch 21/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0011 - r2_score: 0.9926 - val_loss: 6.6576e-04 - val_r2_score: 0.9952\n",
      "Epoch 22/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 9.6847e-04 - r2_score: 0.9938 - val_loss: 0.0012 - val_r2_score: 0.9944\n",
      "Epoch 23/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 9.3957e-04 - r2_score: 0.9939 - val_loss: 0.0021 - val_r2_score: 0.9884\n",
      "Epoch 24/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.0012 - r2_score: 0.9921 - val_loss: 7.1646e-04 - val_r2_score: 0.9954\n",
      "Epoch 25/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 9.6156e-04 - r2_score: 0.9938 - val_loss: 6.4787e-04 - val_r2_score: 0.9958\n",
      "Epoch 26/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 8.8364e-04 - r2_score: 0.9943 - val_loss: 0.0013 - val_r2_score: 0.9930\n",
      "Epoch 27/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 8.9936e-04 - r2_score: 0.9941 - val_loss: 7.7902e-04 - val_r2_score: 0.9938\n",
      "Epoch 28/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 8.8056e-04 - r2_score: 0.9943 - val_loss: 5.1672e-04 - val_r2_score: 0.9963\n",
      "Epoch 29/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.7781e-04 - r2_score: 0.9949 - val_loss: 7.4083e-04 - val_r2_score: 0.9955\n",
      "Epoch 30/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.5618e-04 - r2_score: 0.9945 - val_loss: 5.1151e-04 - val_r2_score: 0.9969\n",
      "Epoch 31/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.7807e-04 - r2_score: 0.9944 - val_loss: 7.4321e-04 - val_r2_score: 0.9958\n",
      "Epoch 32/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.6663e-04 - r2_score: 0.9951 - val_loss: 4.5011e-04 - val_r2_score: 0.9969\n",
      "Epoch 33/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.1946e-04 - r2_score: 0.9940 - val_loss: 8.9047e-04 - val_r2_score: 0.9942\n",
      "Epoch 34/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.0476e-04 - r2_score: 0.9942 - val_loss: 6.6786e-04 - val_r2_score: 0.9964\n",
      "Epoch 35/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7.5601e-04 - r2_score: 0.9952 - val_loss: 0.0018 - val_r2_score: 0.9934\n",
      "Epoch 36/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7.6208e-04 - r2_score: 0.9951 - val_loss: 7.8299e-04 - val_r2_score: 0.9960\n",
      "Epoch 37/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.6803e-04 - r2_score: 0.9946 - val_loss: 7.5714e-04 - val_r2_score: 0.9941\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential() \n",
    "model.add(tf.keras.layers.InputLayer(input_shape=[1001])) \n",
    "model.add(tf.keras.layers.Dense(120, activation='relu')) \n",
    "model.add(tf.keras.layers.Dense(240, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(2, activation='linear')) \n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics = [tf.keras.metrics.R2Score()])\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 5) # Número de iteraciones sin mejora de la pérdida de validación antes de parar el entrenamiento\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val), \n",
    "                    epochs=100,\n",
    "                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7.1557e-04 - r2_score: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0007062221993692219, 0.9944225549697876]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Params fitted\n",
    "with open(f'{data_path}/test/params_fit_NN.pkl', 'wb') as f:\n",
    "    pkl.dump(y_pred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.79131672, 0.52960316],\n",
       "        [0.28326234, 0.16790258],\n",
       "        [2.34309549, 0.84346774],\n",
       "        ...,\n",
       "        [1.84105089, 0.58375466],\n",
       "        [2.97063045, 0.19425141],\n",
       "        [1.00005171, 0.32324333]]),\n",
       " array([[0.8082745 , 0.5556596 ],\n",
       "        [0.25960696, 0.2470391 ],\n",
       "        [2.3231869 , 0.8352717 ],\n",
       "        ...,\n",
       "        [1.8470148 , 0.5899888 ],\n",
       "        [2.968526  , 0.19090614],\n",
       "        [1.0210208 , 0.33873   ]], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIR-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
